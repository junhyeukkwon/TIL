# spark(주유소 데이터 사용)
## spark 시작
- start-dfs && start-yarn && start-mr
- pyspark --master yarn --num-executors 3 &
- zip폴더 업로드
- unzip 파일명
-  mkdir gas_station && mv ./ьг╝ьЬаьЖМ/*.csv ./gas_station
-  hdfs dfs -mkdir /data/gas_station
-  mv 'ьГБы░Шъ╕░ ьг╝ьЬаьЖМ эМРыздъ░Аъ▓й.csv' 2019.csv
-  mv 'эХШы░Шъ╕░ ьг╝ьЬаьЖМ эМРыздъ░Аъ▓й.csv' 2019_2.csv
- trans.py 파일 생성, 실행 (인코딩 문제 해결)
```
import os 

def trans_encoding(dirs):
    with open("{}.txt".format(dirs), "w", encoding='utf-8') as trans:
        with open("{}".format(dirs), "r", encoding='euc-kr') as f:
            for line in f:
                trans.write(line)

for roots, dirs, files in os.walk("/home/hadoop/workspace/data/gas_station"):
    for file in files:
        trans_encoding(roots + '/' + file)
```
- python trans.py
- hdfs dfs -mkdir /data/gas_station
- hdfs dfs -put ./*txt /data/gas_station

## 핸드링
### 데이터 불러오기
```
from pyspark.sql.functions import expr, col, column, sum, count, avg, desc,  row_number
from pyspark.sql.window import Window


spark_df = spark.read.format("csv")\
  .option("header", "true")\
  .option("inferSchema", "true")\
  .load("/data/gas_station/*.txt")
spark_df.printSchema()
```
#### 총 주유소 개수 보기
- spark_df.select(col("번호")).distinct().count()
- spark_df.select(col("번호"), col("상표")).distinct().count()
#### 12/24 시점에 주유소 개수
- df_1224 = spark_df.where(col('기간') == '20191224').select('*')
- df_1224.count()
#### 12/24 시점에서 상표별 주유소 개수
- df_1224.groupby('상표').agg(count(col('상표')).alias('개수')).show()
- 많은 순으로 정렬하기 - df_1224.groupby("상표").agg(count(col('상표'))\
                          .alias("개수"))\
                        .orderBy(desc("개수")).show()
#### 데이터 저장하기(ETL)
- df_1224.write.csv("hdfs:///data/gas")
실행 결과
![image](https://user-images.githubusercontent.com/85923524/188350033-b5a74a40-8433-4810-9828-0382a03588ee.png)
- 셋팅 했을때 파일을 3개 복사해서 저장하는 세팅을 했기 때문에 파일이 3개이다.
#### 구마다 각 주유소 브랜드 개수 확인
- df_1224.groupby("상표", "지역").agg(count(col('상표')).alias("개수")).orderBy('지역', desc('개수') ).show(100)
#### 구마다 개수가 많은걸 순위를 보여줘
df_1224.groupby("상표", "지역").agg(count(col('상표')).alias("개수")).orderBy('지역', desc('개수') )\
    .withColumn("row",row_number().over(Window.partitionBy("지역").orderBy(desc(col("개수"))))).show(100)
#### 지역마다 개수가 가장 많은걸 row컬럼에 순위를 매기고 1위인 것만 보여주기(row 컬럼은 삭제)
- df_1224.groupby("상표", "지역").agg(count(col('상표')).alias("개수")).orderBy('지역', desc('개수') )\
    .withColumn("row",row_number().over(Window.partitionBy("지역").orderBy(desc(col("개수")))))\
    .filter(col("row") == 1).drop("row")\
    .show(100)

### 단순히 추측하는 것이 아니라 통계적인 추론이라는 것을 증명
#### pandas 프레임
- local_df = df_1224.toPandas()
#### scipy 설치
- pip install scipy
#### scipy 에서 ttest 진행
```
from  scipy.stats  import  ttest_ind

t, p = ttest_ind(local_df.loc[local_df['셀프여부'] == '일반', '휘발유'], local_df.loc[local_df['셀프여부'] == '셀프', '휘발유'])   
```
이때에 p-value가 0.05보다 훨씬 작으므로 일반 과 셀프가 가격이 차이가 있다는 것이 채택이된다(대립가설 채택)
